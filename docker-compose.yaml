version: '3'
services:
  kafka-standalone:
    image: 'apache/kafka:3.7.0'
    hostname: kafka-standalone
    container_name: kafka-standalone
    ports:
      - '8083:8083'
      - '9092:9092'
    environment:
      # Ref: https://github.com/apache/kafka/blob/3.7.0/docker/examples/jvm/single-node/plaintext/docker-compose.yml
      # Most of these are default values from config/kraft/server.properties. We only want to tweak the listeners but 
      # we need to set all the other properties as well for the broker/controller to work as expected. 
      - KAFKA_NODE_ID=1
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT_HOST://localhost:9092,PLAINTEXT://kafka-standalone:19092
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka-standalone:29093
      - KAFKA_LISTENERS=CONTROLLER://:29093,PLAINTEXT_HOST://:9092,PLAINTEXT://:19092
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_LOG_DIRS=/tmp/kraft-combined-logs
    user: root # Required to write back to host volume
    volumes:
      - "$PWD/kafka/config:/opt/kafka/config-cdc"
      - "$PWD/kafka/plugins:/opt/kafka/plugins"
      - "$PWD/data/kafka/tmp:/tmp"
      - "$PWD/data/kafka/out:/out"
    deploy:
      replicas: 1

  kafka-postgres:
    hostname: kafka-postgres
    container_name: kafka-postgres
    image: 'postgres:16.2'
    ports:
      - '5433:5432'
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    volumes:
      - "$PWD/postgres/postgresql.conf:/etc/postgresql/postgresql.conf"
      - "$PWD/postgres/scripts/seed:/docker-entrypoint-initdb.d"
    deploy:
      replicas: 1

  kafka-spark:
    profiles: 
      - spark
    image: 'apache/spark:3.5.1-java17-python3'
    container_name: kafka-spark
    # This will take time because it will download all the kafka dependencies for spark
    command: /opt/spark/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0 --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/.ivy -Divy.home=/.ivy" /scripts/consumer.py
    # For debugging, pyspark shell can be used
    # command: /opt/spark/bin/pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0 --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/.ivy -Divy.home=/.ivy"
    user: root # Required to write back to host volume
    volumes:
      - "$PWD/spark/scripts/:/scripts"
      - "$PWD/data/spark/.ivy/:/.ivy"
      - "$PWD/data/spark/out/:/out"
